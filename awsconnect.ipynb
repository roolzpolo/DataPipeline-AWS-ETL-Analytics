{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50850fbe-d055-46c4-ac81-14f2f47f337f",
   "metadata": {},
   "source": [
    "# INGESTION DE DATOS TRANSACCIONALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815fc77b-f961-4e59-a032-7ec517dec667",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONFIGURACION DE AWS RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70668ec4-4754-401e-949c-2fe2c1ea8909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias necesarias\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import configparser\n",
    "from faker import Faker\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9280023d-8ab5-4632-b50b-777e08e720f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config.cfg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Documento privado de claves\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74417b6c-d9f8-4336-9f06-5133c941a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificacion con AWS\n",
    "aws_rds_conn = boto3.client('rds', aws_access_key_id=config.get('IAM','ACCESS_KEY'),\n",
    "                             aws_secret_access_key=config.get('IAM','SECRET_ACCESS_KEY'),\n",
    "                             region_name='us-east-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11570cc0-8fd9-41f3-9560-627c093f6047",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instancias Disponibles : ['banco-transactional']\n"
     ]
    }
   ],
   "source": [
    "#Verificacion de instancias creadas anteriormente.\n",
    "\n",
    "rds_instances_ids = []\n",
    "aws_response = aws_rds_conn.describe_db_instances() \n",
    "\n",
    "for response in aws_response['DBInstances']:\n",
    "    rds_instances_ids.append(response['DBInstanceIdentifier'])\n",
    "\n",
    "print(f\"Instancias Disponibles : {rds_instances_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "575a3206-be0b-47b6-83ae-8d1ee866c3c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La instancia ya existe\n"
     ]
    }
   ],
   "source": [
    "#creacion de la base de datos\n",
    "\n",
    "try:\n",
    "    response = aws_rds_conn.create_db_instance(\n",
    "        DBInstanceIdentifier = config.get('TRANSACC','DB_INSTANCE_ID'),\n",
    "        DBName = config.get('TRANSACC','DB_NAME'),\n",
    "        DBInstanceClass = 'db.t3.micro',\n",
    "        Engine = 'postgres',\n",
    "        MasterUsername = config.get('TRANSACC','DB_USER'),\n",
    "        MasterUserPassword = config.get('TRANSACC','DB_PASSWORD'),\n",
    "        Port = int(config.get('TRANSACC','DB_PORT')),\n",
    "        PubliclyAccessible = True,\n",
    "        VpcSecurityGroupIds = [config.get('VPC','SECURITY_GROUP')],\n",
    "        AllocatedStorage = 15\n",
    "               )\n",
    "    print(response)\n",
    "except aws_rds_conn.exceptions.DBInstanceAlreadyExistsFault as ex:\n",
    "    print('La instancia ya existe')\n",
    "except Exeption as ex:\n",
    "    print('ERROR', ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14a9450-1135-4573-8815-cfca8c6fd3d2",
   "metadata": {},
   "source": [
    "### Obtencion del hostname de las instancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03a3c861-20c5-4bcb-85d1-45afe0181ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banco-transactional.c1m44mee4c6c.us-east-1.rds.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "# codigo para obtener el hostname\n",
    "\n",
    "try: \n",
    "    instance = aws_rds_conn.describe_db_instances(DBInstanceIdentifier = config.get('TRANSACC','DB_INSTANCE_ID'))\n",
    "    RDS_HOSTNAME = instance.get('DBInstances')[0].get('Endpoint').get('Address')\n",
    "    print(RDS_HOSTNAME)\n",
    "except Exception as ex:\n",
    "    print('Error', ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1d65c7-128c-435b-ab9d-5a2358dc0968",
   "metadata": {},
   "source": [
    "### Conexion de base de datos desde python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e4899ec-13f8-40c0-8205-3d2da6e657ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sql_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0369c798-5f73-43a2-8e12-a650b6fe87fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de datos creada exitosamente\n"
     ]
    }
   ],
   "source": [
    "#creacion de database de datos\n",
    "try:\n",
    "    db_pg_conn = psycopg2.connect(\n",
    "                    dbname = config.get('TRANSACC','DB_NAME'),\n",
    "                    user = config.get('TRANSACC','DB_USER'),\n",
    "                    password = config.get('TRANSACC','DB_PASSWORD'),\n",
    "                    host = RDS_HOSTNAME,\n",
    "                    port = config.get('TRANSACC','DB_PORT')\n",
    "    )\n",
    "    cursor = db_pg_conn.cursor()\n",
    "    cursor.execute(sql_queries.DDL_QUERY)\n",
    "    db_pg_conn.commit()\n",
    "    print('Base de datos creada exitosamente')\n",
    "\n",
    "except Exception as ex:\n",
    "    print('ERROR', ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f203ffea-7560-426e-8df3-c010995cf596",
   "metadata": {},
   "source": [
    "## Generacion de datos con Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1faeac3-540d-4565-a00b-daa3034c1590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carga de librerias nuevamente\n",
    "from faker import Faker\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from configparser import ConfigParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7bb63a6-49d9-46cc-9629-97ffa5a2cb19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Conectar a la base de datos PostgreSQL usando SQLAlchemy\n",
    "\n",
    "driver = f\"\"\"postgresql://{config.get('TRANSACC', 'DB_USER')}:{config.get('TRANSACC', 'DB_PASSWORD')}@{RDS_HOSTNAME}:{config.get('TRANSACC', 'DB_PORT')}/{config.get('TRANSACC', 'DB_NAME')}\"\"\"\n",
    "engine = create_engine(driver)\n",
    "# insertData2SQL(data_tipo_transacciones, 'tipo_transacciones', driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f6848b-5273-434f-b2b2-5284ece2c6ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfb7d1aa-cdf5-4498-af6e-5e946fa663e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han insertado 1000 nuevos registros en la tabla categoria.\n"
     ]
    }
   ],
   "source": [
    "#ingreso de data para 'CATEGORIA'\n",
    "# Inicializar Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Función para generar datos para la tabla 'categoria'\n",
    "def generate_categoria_data(n):\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        data.append({\n",
    "            \"nombre\": fake.word(),\n",
    "            \"descripcion\": fake.text(max_nb_chars=255),\n",
    "            \"estado\": fake.boolean()\n",
    "        })\n",
    "    return data\n",
    "\n",
    "# Insertar datos a la base de datos\n",
    "def insertData2SQL(data, table_name, engine):\n",
    "    df_data = pd.DataFrame(data)\n",
    "    try:\n",
    "        response = df_data.to_sql(table_name, engine, index=False, if_exists='append')\n",
    "        print(f\"Se han insertado {len(df_data)} nuevos registros en la tabla {table_name}.\")\n",
    "    except Exception as ex:\n",
    "        print(f\"Error al insertar datos: {ex}\")\n",
    "\n",
    "# Generar 1000 registros de datos para 'categoria'\n",
    "data_categoria = generate_categoria_data(1000)\n",
    "\n",
    "# Crear motor SQLAlchemy\n",
    "engine = create_engine(driver)\n",
    "\n",
    "# Insertar datos generados en la tabla 'categoria'\n",
    "insertData2SQL(data_categoria, 'categoria', driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe61bef7-a823-4520-9cf4-84cec48296a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han insertado 1000 nuevos registros en la tabla rol.\n"
     ]
    }
   ],
   "source": [
    "# INGRESO DE DATA PARA ROL\n",
    "# Inicializar Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Función para generar datos para la tabla 'rol'\n",
    "def generate_rol_data(n):\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        data.append({\n",
    "            \"nombre\": fake.job()[:30],  # Genera nombres de roles basados en tipos de trabajos\n",
    "            \"descripcion\": fake.text(max_nb_chars=255),  # Descripción falsa\n",
    "            \"estado\": fake.boolean()  # Estado aleatorio\n",
    "        })\n",
    "    return data\n",
    "\n",
    "# Insertar datos a la base de datos\n",
    "def insertData2SQL(data, table_name, engine):\n",
    "    df_data = pd.DataFrame(data)\n",
    "    try:\n",
    "        response = df_data.to_sql(table_name, engine, index=False, if_exists='append')\n",
    "        print(f\"Se han insertado {len(df_data)} nuevos registros en la tabla {table_name}.\")\n",
    "    except Exception as ex:\n",
    "        print(f\"Error al insertar datos: {ex}\")\n",
    "\n",
    "# Generar 1000 registros de datos para 'categoria'\n",
    "data_rol = generate_rol_data(1000)\n",
    "\n",
    "# Crear motor SQLAlchemy\n",
    "engine = create_engine(driver)\n",
    "\n",
    "# Insertar datos generados en la tabla 'categoria'\n",
    "insertData2SQL(data_rol, 'rol', driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "868a9199-d9da-4e16-ad5a-bc2668c0c266",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sessionmaker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Crear el motor SQLAlchemy\u001b[39;00m\n\u001b[1;32m      6\u001b[0m engine \u001b[38;5;241m=\u001b[39m create_engine(driver)\n\u001b[0;32m----> 7\u001b[0m Session \u001b[38;5;241m=\u001b[39m sessionmaker(bind\u001b[38;5;241m=\u001b[39mengine)\n\u001b[1;32m      8\u001b[0m session \u001b[38;5;241m=\u001b[39m Session()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Función para obtener los roles existentes\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sessionmaker' is not defined"
     ]
    }
   ],
   "source": [
    "#INGRESO DE DATA PARA USUARIO\n",
    "# Inicializar Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Crear el motor SQLAlchemy\n",
    "engine = create_engine(driver)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Función para obtener los roles existentes\n",
    "def get_existing_roles(session):\n",
    "    results = session.execute(text(\"SELECT idrol FROM rol\"))\n",
    "    existing_roles = [row[0] for row in results]\n",
    "    return existing_roles\n",
    "\n",
    "# Obtener los roles existentes\n",
    "existing_roles = get_existing_roles(session)\n",
    "\n",
    "# Función para generar datos para la tabla 'usuario'\n",
    "def generate_usuario_data(n, existing_roles):\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        data.append({\n",
    "            \"idrol\": fake.random.choice(existing_roles),\n",
    "            \"nombre\": fake.name()[:100],\n",
    "            \"tipo_documento\": fake.random.choice(['DNI', 'PAS', 'RUC', 'CE'])[:20],\n",
    "            \"num_documento\": fake.bothify(text='########')[:20],\n",
    "            \"direccion\": fake.address()[:70],\n",
    "            \"telefono\": fake.phone_number()[:20],\n",
    "            \"email\": fake.email()[:50],\n",
    "            \"clave\": fake.password(length=10, special_chars=True, digits=True, upper_case=True, lower_case=True)[:50],\n",
    "            \"estado\": fake.boolean()\n",
    "        })\n",
    "    return data\n",
    "\n",
    "# Función para insertar datos en la base de datos\n",
    "def insertData2SQL(data, table_name, engine):\n",
    "    df_data = pd.DataFrame(data)\n",
    "    try:\n",
    "        response = df_data.to_sql(table_name, engine, index=False, if_exists='append')\n",
    "        print(f\"Se han insertado {len(df_data)} nuevos registros en la tabla {table_name}.\")\n",
    "    except Exception as ex:\n",
    "        print(f\"Error al insertar datos: {ex}\")\n",
    "\n",
    "# Generar 1000 registros de datos para 'usuario'\n",
    "data_usuario = generate_usuario_data(1000, existing_roles)\n",
    "\n",
    "# Insertar datos generados en la tabla 'usuario'\n",
    "insertData2SQL(data_usuario, 'usuario', driver)\n",
    "\n",
    "# Cerrar la sesión\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce58afd-86aa-49bf-b0a5-eef000fe1556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INGRESO DE DATA PARA PERSONA\n",
    "# Inicializar Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Función para generar datos para la tabla 'persona'\n",
    "def generate_persona_data(n):\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        tipo_persona_choice = fake.random_element(elements=('Natural', 'Jurídica'))\n",
    "        tipo_documento_choice = fake.random_element(elements=('DNI', 'PAS', 'RUC', 'CE'))\n",
    "        data.append({\n",
    "            \"tipo_persona\": tipo_persona_choice[:20],  # Asegurar max 20 caracteres\n",
    "            \"nombre\": fake.name()[:100],  # Asegurar max 100 caracteres\n",
    "            \"tipo_documento\": tipo_documento_choice[:20],  # Asegurar max 20 caracteres\n",
    "            \"num_documento\": fake.bothify(text='?#######', letters='ABCDEFGHJKLMNPQRSTUVWXYZ')[:20],  # Asegurar max 20 caracteres\n",
    "            \"direccion\": fake.street_address()[:70],  # Asegurar max 70 caracteres\n",
    "            \"telefono\": fake.phone_number()[:20],  # Asegurar max 20 caracteres\n",
    "            \"email\": fake.email()[:50]  # Asegurar max 50 caracteres\n",
    "        })\n",
    "    return data\n",
    "\n",
    "# Insertar datos a la base de datos\n",
    "def insertData2SQL(data, table_name, engine):\n",
    "    df_data = pd.DataFrame(data)\n",
    "    try:\n",
    "        response = df_data.to_sql(table_name, engine, index=False, if_exists='append')\n",
    "        print(f\"Se han insertado {len(df_data)} nuevos registros en la tabla {table_name}.\")\n",
    "    except Exception as ex:\n",
    "        print(f\"Error al insertar datos: {ex}\")\n",
    "\n",
    "# Generar 1000 registros de datos para 'persona'\n",
    "data_persona = generate_persona_data(1000)\n",
    "\n",
    "# Crear motor SQLAlchemy\n",
    "engine = create_engine(driver)\n",
    "\n",
    "# Insertar datos generados en la tabla 'persona'\n",
    "insertData2SQL(data_persona, 'persona', driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efe9584-8894-440f-a452-4e73bcde238e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#INGRESO DE DATA PARA VENTA\n",
    "\n",
    "# Inicializar Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Crear el motor SQLAlchemy\n",
    "engine = create_engine(driver)  \n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "def get_existing_personas(session):\n",
    "    results = session.execute(text(\"SELECT idpersona FROM persona\"))\n",
    "    existing_personas = [row[0] for row in results]  \n",
    "    return existing_personas\n",
    "\n",
    "def get_existing_usuarios(session):\n",
    "    results = session.execute(text(\"SELECT idusuario FROM usuario\"))\n",
    "    existing_usuarios = [row[0] for row in results]  \n",
    "    return existing_usuarios\n",
    "\n",
    "# Obtener los IDs existentes\n",
    "existing_personas = get_existing_personas(session)\n",
    "existing_usuarios = get_existing_usuarios(session)\n",
    "\n",
    "# Función para generar datos para la tabla 'venta'\n",
    "def generate_venta_data(n, existing_personas, existing_usuarios):\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        data.append({\n",
    "            \"idcliente\": fake.random.choice(existing_personas),\n",
    "            \"idusuario\": fake.random.choice(existing_usuarios),\n",
    "            \"tipo_comprobante\": fake.random_element(elements=('Factura', 'Boleta', 'Ticket'))[:20],\n",
    "            \"serie_comprobante\": fake.bothify(text='??###')[:7],\n",
    "            \"num_comprobante\": fake.bothify(text='#######')[:10],\n",
    "            \"fecha\": datetime.now(),\n",
    "            \"impuesto\": round(fake.random_number(digits=2) + fake.random.random(), 2),\n",
    "            \"total\": round(fake.random_number(digits=5) + fake.random.random(), 2),\n",
    "            \"estado\": fake.random_element(elements=('Activo', 'Cancelado', 'Pendiente'))[:20]\n",
    "        })\n",
    "    return data\n",
    "\n",
    "# Función para insertar datos en la base de datos\n",
    "def insertData2SQL(data, table_name, engine):\n",
    "    df_data = pd.DataFrame(data)\n",
    "    try:\n",
    "        df_data.to_sql(table_name, engine, index=False, if_exists='append')\n",
    "        print(f\"Se han insertado {len(df_data)} nuevos registros en la tabla {table_name}.\")\n",
    "    except Exception as ex:\n",
    "        print(f\"Error al insertar datos: {ex}\")\n",
    "\n",
    "# Generar 1000 registros de datos para 'venta'\n",
    "data_venta = generate_venta_data(1000, existing_personas, existing_usuarios)\n",
    "\n",
    "# Insertar datos generados en la tabla 'venta'\n",
    "insertData2SQL(data_venta, 'venta', driver)\n",
    "\n",
    "# Cerrar la sesión\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c27e9b-318c-4b52-bed7-9cd7340cf605",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#INGRESO DE DATA PARA ARTICULO\n",
    "\n",
    "# Inicializar Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Crear el motor SQLAlchemy\n",
    "engine = create_engine(driver)  \n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Función para obtener los ID de categorías existentes\n",
    "def get_existing_categorias(session):\n",
    "    results = session.execute(text(\"SELECT idcategoria FROM categoria\"))\n",
    "    existing_categorias = [row[0] for row in results]  # Corregido para usar el nombre correcto\n",
    "    return existing_categorias\n",
    "\n",
    "# Obtener los IDs existentes\n",
    "existing_categorias = get_existing_categorias(session)\n",
    "\n",
    "# Función para generar datos para la tabla 'articulo'\n",
    "def generate_articulo_data(n, existing_categorias):\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        data.append({\n",
    "            \"idcategoria\": fake.random.choice(existing_categorias),\n",
    "            \"codigo\": fake.bothify(text='??#####')[:50],  # Código con un máximo de 50 caracteres\n",
    "            \"nombre\": fake.company()[:100],  # Nombre con un máximo de 100 caracteres\n",
    "            \"precio_venta\": round(fake.random_number(digits=5) + fake.random.random(), 2),\n",
    "            \"stock\": fake.random_int(min=0, max=1000),\n",
    "            \"descripcion\": fake.text(max_nb_chars=255),  # Descripción con un máximo de 255 caracteres\n",
    "            \"imagen\": fake.file_name(category='image', extension='png')[:20],  # Imagen con un máximo de 20 caracteres\n",
    "            \"estado\": fake.boolean()\n",
    "        })\n",
    "    return data\n",
    "\n",
    "\n",
    "# Función para insertar datos en la base de datos\n",
    "def insertData2SQL(data, table_name, engine):\n",
    "    df_data = pd.DataFrame(data)\n",
    "    try:\n",
    "        df_data.to_sql(table_name, engine, index=False, if_exists='append')\n",
    "        print(f\"Se han insertado {len(df_data)} nuevos registros en la tabla {table_name}.\")\n",
    "    except Exception as ex:\n",
    "        print(f\"Error al insertar datos: {ex}\")\n",
    "\n",
    "# Generar 1000 registros de datos para 'articulo'\n",
    "data_articulo = generate_articulo_data(1000, existing_categorias)\n",
    "\n",
    "# Insertar datos generados en la tabla 'articulo'\n",
    "insertData2SQL(data_articulo, 'articulo', driver)\n",
    "\n",
    "# Cerrar la sesión\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa0ce8-53c3-446d-a55d-ba66acc916eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#INGRESO DE DATA PARA detalle de venta\n",
    "\n",
    "# Inicializar Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Crear el motor SQLAlchemy\n",
    "engine = create_engine(driver)  \n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "def get_existing_ventas(session):\n",
    "    results = session.execute(text(\"SELECT idventa FROM venta\"))\n",
    "    existing_ventas = [row[0] for row in results] \n",
    "    return existing_ventas\n",
    "\n",
    "def get_existing_articulos(session):\n",
    "    results = session.execute(text(\"SELECT idarticulo FROM articulo\"))\n",
    "    existing_articulos = [row[0] for row in results]  \n",
    "    return existing_articulos\n",
    "\n",
    "# Obtener los IDs existentes\n",
    "existing_ventas = get_existing_personas(session)\n",
    "existing_articulos = get_existing_usuarios(session)\n",
    "\n",
    "# Función para generar datos para la tabla 'detalle de venta'\n",
    "def generate_detalle_venta_data(n, existing_ventas, existing_articulos):\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        idventa = fake.random.choice(existing_ventas)\n",
    "        idarticulo = fake.random.choice(existing_articulos)\n",
    "        cantidad = fake.random_int(min=1, max=100)\n",
    "        precio = round(fake.random_number(digits=7) + fake.random.random(), 2)  # NUMERIC(11, 2)\n",
    "        descuento = round(fake.random_number(digits=4) * 0.01, 2)  # NUMERIC(11, 2), descuento realista\n",
    "\n",
    "        data.append({\n",
    "            \"idventa\": idventa,\n",
    "            \"idarticulo\": idarticulo,\n",
    "            \"cantidad\": cantidad,\n",
    "            \"precio\": precio,\n",
    "            \"descuento\": descuento\n",
    "        })\n",
    "    return data\n",
    "\n",
    "\n",
    "# Función para insertar datos en la base de datos\n",
    "def insertData2SQL(data, table_name, engine):\n",
    "    df_data = pd.DataFrame(data)\n",
    "    try:\n",
    "        df_data.to_sql(table_name, engine, index=False, if_exists='append')\n",
    "        print(f\"Se han insertado {len(df_data)} nuevos registros en la tabla {table_name}.\")\n",
    "    except Exception as ex:\n",
    "        print(f\"Error al insertar datos: {ex}\")\n",
    "\n",
    "# Generar 1000 registros de datos para 'detalle venta'\n",
    "data_detalle_venta = generate_detalle_venta_data(1000, existing_ventas, existing_articulos)\n",
    "\n",
    "# Insertar datos generados en la tabla 'detalle venta'\n",
    "insertData2SQL(data_detalle_venta, 'detalle_venta', driver)\n",
    "\n",
    "# Cerrar la sesión\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc1572d-e4fd-46a1-adb3-3a5553491619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#INGRESO DE DATA PARA ingreso\n",
    "# Inicializar Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Crear el motor SQLAlchemy\n",
    "engine = create_engine(driver)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "def get_existing_proveedores(session):\n",
    "    results = session.execute(text(\"SELECT idpersona FROM persona\"))\n",
    "    existing_proveedores = [row[0] for row in results]\n",
    "    return existing_proveedores\n",
    "\n",
    "def get_existing_usuarios(session):\n",
    "    results = session.execute(text(\"SELECT idusuario FROM usuario\"))\n",
    "    existing_usuarios = [row[0] for row in results]\n",
    "    return existing_usuarios\n",
    "\n",
    "# Obtener los IDs existentes\n",
    "existing_proveedores = get_existing_proveedores(session)\n",
    "existing_usuarios = get_existing_usuarios(session)\n",
    "\n",
    "# Función para generar datos para la tabla 'ingreso'\n",
    "def generate_ingreso_data(n, existing_proveedores, existing_usuarios):\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        data.append({\n",
    "            \"idproveedor\": fake.random.choice(existing_proveedores),\n",
    "            \"idusuario\": fake.random.choice(existing_usuarios),\n",
    "            \"tipo_comprobante\": fake.random_element(elements=('Factura', 'Boleta', 'Nota de Crédito'))[:20],\n",
    "            \"serie_comprobante\": fake.bothify(text='??###')[:7],\n",
    "            \"num_comprobante\": fake.bothify(text='#######')[:10],\n",
    "            \"fecha\": fake.date_time_this_year(before_now=True, after_now=False),\n",
    "            \"impuesto\": round(fake.random_number(digits=2) + fake.random.random(), 2),\n",
    "            \"total\": round(fake.random_number(digits=5) + fake.random.random(), 2),\n",
    "            \"estado\": fake.random_element(elements=('Activo', 'Inactivo'))[:20]\n",
    "        })\n",
    "    return data\n",
    "\n",
    "\n",
    "# Función para insertar datos en la base de datos\n",
    "def insertData2SQL(data, table_name, engine):\n",
    "    df_data = pd.DataFrame(data)\n",
    "    try:\n",
    "        df_data.to_sql(table_name, engine, index=False, if_exists='append')\n",
    "        print(f\"Se han insertado {len(df_data)} nuevos registros en la tabla {table_name}.\")\n",
    "    except Exception as ex:\n",
    "        print(f\"Error al insertar datos: {ex}\")\n",
    "\n",
    "# Generar 1000 registros de datos para 'ingreso'\n",
    "data_ingreso = generate_ingreso_data(1000, existing_proveedores, existing_usuarios)\n",
    "\n",
    "# Insertar datos generados en la tabla 'ingreso'\n",
    "insertData2SQL(data_ingreso, 'ingreso', driver)\n",
    "\n",
    "# Cerrar la sesión\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81808d45-4163-43fc-9ce6-06f9d794a0cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#INGRESO DE DATA PARA detalle ingreso\n",
    "# Inicializar Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Crear el motor SQLAlchemy\n",
    "engine = create_engine(driver)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "def get_existing_ingresos(session):\n",
    "    results = session.execute(text(\"SELECT idingreso FROM ingreso\"))\n",
    "    existing_ingresos = [row[0] for row in results]\n",
    "    return existing_ingresos\n",
    "\n",
    "def get_existing_articulos(session):\n",
    "    results = session.execute(text(\"SELECT idarticulo FROM articulo\"))\n",
    "    existing_articulos = [row[0] for row in results]\n",
    "    return existing_articulos\n",
    "\n",
    "# Obtener los IDs existentes\n",
    "existing_ingresos = get_existing_ingresos(session)\n",
    "existing_articulos = get_existing_articulos(session)\n",
    "\n",
    "# Función para generar datos para la tabla 'detalle_ingreso'\n",
    "def generate_detalle_ingreso_data(n, existing_ingresos, existing_articulos):\n",
    "    data = []\n",
    "    for _ in range(n):\n",
    "        idingreso = fake.random.choice(existing_ingresos)\n",
    "        idarticulo = fake.random.choice(existing_articulos)\n",
    "        cantidad = fake.random_int(min=1, max=100)\n",
    "        precio = round(fake.random_number(digits=7) + fake.random.random(), 2)  # NUMERIC(11, 2)\n",
    "\n",
    "        data.append({\n",
    "            \"idingreso\": idingreso,\n",
    "            \"idarticulo\": idarticulo,\n",
    "            \"cantidad\": cantidad,\n",
    "            \"precio\": precio\n",
    "        })\n",
    "    return data\n",
    "\n",
    "\n",
    "# Función para insertar datos en la base de datos\n",
    "def insertData2SQL(data, table_name, engine):\n",
    "    df_data = pd.DataFrame(data)\n",
    "    try:\n",
    "        df_data.to_sql(table_name, engine, index=False, if_exists='append')\n",
    "        print(f\"Se han insertado {len(df_data)} nuevos registros en la tabla {table_name}.\")\n",
    "    except Exception as ex:\n",
    "        print(f\"Error al insertar datos: {ex}\")\n",
    "\n",
    "# Generar 1000 registros de datos para 'detalle ingreso'\n",
    "data_detalle_ingreso = generate_detalle_ingreso_data(1000, existing_ingresos, existing_articulos)\n",
    "\n",
    "# Insertar datos generados en la tabla 'detalle_ingreso'\n",
    "insertData2SQL(data_detalle_ingreso, 'detalle_ingreso', driver)\n",
    "\n",
    "# Cerrar la sesión\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db20fb66-ed7d-4fbf-94a5-c13e5be7e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analisis de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b4e3fc6-e966-4cea-8064-811d82eea8dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "datetime64 type does not support sum operations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m df_venta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmes\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_venta[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfecha\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth  \u001b[38;5;66;03m# Crear una columna 'mes' extraída de 'fecha'\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Agrupar por mes y sumar las ventas\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m ventas_por_mes \u001b[38;5;241m=\u001b[39m df_venta\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmes\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Gráfico de las ventas por mes\u001b[39;00m\n\u001b[1;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:3146\u001b[0m, in \u001b[0;36mGroupBy.sum\u001b[0;34m(self, numeric_only, min_count, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   3141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3142\u001b[0m     \u001b[38;5;66;03m# If we are grouping on categoricals we want unobserved categories to\u001b[39;00m\n\u001b[1;32m   3143\u001b[0m     \u001b[38;5;66;03m# return zero, rather than the default of NaN which the reindexing in\u001b[39;00m\n\u001b[1;32m   3144\u001b[0m     \u001b[38;5;66;03m# _agg_general() returns. GH #31422\u001b[39;00m\n\u001b[1;32m   3145\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m com\u001b[38;5;241m.\u001b[39mtemp_setattr(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobserved\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m-> 3146\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_general(\n\u001b[1;32m   3147\u001b[0m             numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[1;32m   3148\u001b[0m             min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m   3149\u001b[0m             alias\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3150\u001b[0m             npfunc\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msum,\n\u001b[1;32m   3151\u001b[0m         )\n\u001b[1;32m   3153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_output(result, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1906\u001b[0m, in \u001b[0;36mGroupBy._agg_general\u001b[0;34m(self, numeric_only, min_count, alias, npfunc, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_agg_general\u001b[39m(\n\u001b[1;32m   1898\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1904\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1905\u001b[0m ):\n\u001b[0;32m-> 1906\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   1907\u001b[0m         how\u001b[38;5;241m=\u001b[39malias,\n\u001b[1;32m   1908\u001b[0m         alt\u001b[38;5;241m=\u001b[39mnpfunc,\n\u001b[1;32m   1909\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[1;32m   1910\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m   1911\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1912\u001b[0m     )\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1998\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[1;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1998\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[1;32m   1999\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:1472\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1470\u001b[0m             result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m   1471\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1472\u001b[0m         applied \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mapply(func)\n\u001b[1;32m   1473\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m   1475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result_blocks) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/blocks.py:393\u001b[0m, in \u001b[0;36mBlock.apply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    395\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1973\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marray_func\u001b[39m(values: ArrayLike) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[1;32m   1972\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1973\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[1;32m   1974\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1975\u001b[0m             values,\n\u001b[1;32m   1976\u001b[0m             how,\n\u001b[1;32m   1977\u001b[0m             axis\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1978\u001b[0m             min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m   1979\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1980\u001b[0m         )\n\u001b[1;32m   1981\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1982\u001b[0m         \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[1;32m   1983\u001b[0m         \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[1;32m   1984\u001b[0m         \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[1;32m   1985\u001b[0m         \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[1;32m   1986\u001b[0m         \u001b[38;5;66;03m# TODO: avoid special casing SparseArray here\u001b[39;00m\n\u001b[1;32m   1987\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, SparseArray):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:831\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[0;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[1;32m    829\u001b[0m ids, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_info\n\u001b[1;32m    830\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n\u001b[0;32m--> 831\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cy_op\u001b[38;5;241m.\u001b[39mcython_operation(\n\u001b[1;32m    832\u001b[0m     values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[1;32m    833\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m    834\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m    835\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    836\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    838\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/groupby/ops.py:541\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[0;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_axis(axis, values)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_groupby_op(\n\u001b[1;32m    542\u001b[0m         how\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow,\n\u001b[1;32m    543\u001b[0m         has_dropped_na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_dropped_na,\n\u001b[1;32m    544\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m    545\u001b[0m         ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[1;32m    546\u001b[0m         ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_op_ndim_compat(\n\u001b[1;32m    551\u001b[0m     values,\n\u001b[1;32m    552\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    557\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/datetimelike.py:1669\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._groupby_op\u001b[0;34m(self, how, has_dropped_na, min_count, ngroups, ids, **kwargs)\u001b[0m\n\u001b[1;32m   1666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1667\u001b[0m     \u001b[38;5;66;03m# Adding/multiplying datetimes is not valid\u001b[39;00m\n\u001b[1;32m   1668\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprod\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcumsum\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcumprod\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvar\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskew\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m-> 1669\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime64 type does not support \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m operations\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1670\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m   1671\u001b[0m         \u001b[38;5;66;03m# GH#34479\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1673\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with datetime64 dtypes is deprecated and will raise in a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1674\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuture version. Use (obj != pd.Timestamp(0)).\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1675\u001b[0m             \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1676\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1677\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: datetime64 type does not support sum operations"
     ]
    }
   ],
   "source": [
    "driver = f\"\"\"postgresql://{config.get('TRANSACC', 'DB_USER')}:{config.get('TRANSACC', 'DB_PASSWORD')}@{RDS_HOSTNAME}:{config.get('TRANSACC', 'DB_PORT')}/{config.get('TRANSACC', 'DB_NAME')}\"\"\"\n",
    "engine = create_engine(driver)\n",
    "# Extraer datos de ventas\n",
    "query_ventas = \"SELECT * FROM venta\"\n",
    "df_venta = pd.read_sql(query_ventas, engine)\n",
    "df_venta['mes'] = df_venta['fecha'].dt.month  # Crear una columna 'mes' extraída de 'fecha'\n",
    "\n",
    "# Agrupar por mes y sumar las ventas\n",
    "ventas_por_mes = df_venta.groupby('mes').sum()['total']\n",
    "\n",
    "# Gráfico de las ventas por mes\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=ventas_por_mes.index, y=ventas_por_mes.values)\n",
    "plt.title('Ventas Totales por Mes')\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Ventas Totales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe8425d-a1fa-4abd-8abd-c62eded184d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
